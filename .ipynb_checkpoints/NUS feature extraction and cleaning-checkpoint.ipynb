{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Aug  6 20:05:54 2019\n",
    "\n",
    "@author: Akshay\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d=pd.read_csv(\"train2.tsv\",delimiter='\\t',header=None)\n",
    "test_d=pd.read_csv(\"test2.tsv\",delimiter='\\t',header=None)\n",
    "val_d=pd.read_csv(\"val2.tsv\",delimiter='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d.drop(columns=[0,1,4,5,6,7,8],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d.drop(columns=[0,1,4,5,6,7,8],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_d.drop(columns=[0,1,4,5,6,7,8],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colNorm(df):\n",
    "    temp=df.sum(axis=1)\n",
    "    for i in range(9,14):\n",
    "        df[i]=df[i]/temp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d=colNorm(train_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d=colNorm(test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_d=colNorm(val_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d.fillna(value=\"\",inplace=True)\n",
    "test_d.fillna(value=\"\",inplace=True)\n",
    "val_d.fillna(value=\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d[3] = train_d[3].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "train_d[14] = train_d[14].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "train_d[15] = train_d[15].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "test_d[3] = test_d[3].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "test_d[14] = test_d[14].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "test_d[15] = test_d[15].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "val_d[3] = val_d[3].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "val_d[14] = val_d[14].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "val_d[15] = val_d[15].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d[3] = train_d[3].str.replace('[^\\w\\s]','')\n",
    "train_d[14] = train_d[14].str.replace('[^\\w\\s]','')\n",
    "train_d[15] = train_d[15].str.replace('[^\\w\\s]','')\n",
    "test_d[3] = test_d[3].str.replace('[^\\w\\s]','')\n",
    "test_d[14] = test_d[14].str.replace('[^\\w\\s]','')\n",
    "test_d[15] = test_d[15].str.replace('[^\\w\\s]','')\n",
    "val_d[3] = val_d[3].str.replace('[^\\w\\s]','')\n",
    "val_d[14] = val_d[14].str.replace('[^\\w\\s]','')\n",
    "val_d[15] = val_d[15].str.replace('[^\\w\\s]','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "train_d[3] = train_d[3].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "train_d[14] = train_d[14].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "train_d[15] = train_d[15].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "test_d[3] = test_d[3].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "test_d[14] = test_d[14].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "test_d[15] = test_d[15].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "val_d[3] = val_d[3].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "val_d[14] = val_d[14].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "val_d[15] = val_d[15].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "train_d[3] = train_d[3].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train_d[14] = train_d[14].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train_d[15] = train_d[15].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "test_d[3] = test_d[3].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "test_d[14] = test_d[14].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "test_d[15] = test_d[15].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "val_d[3] = val_d[3].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "val_d[14] = val_d[14].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "val_d[15] = val_d[15].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "val_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d[16]=train_d[3]+\" <sep1> \"+train_d[14]+\" <sep2> \"+train_d[15]\n",
    "test_d[16]=test_d[3]+\" <sep1> \"+test_d[14]+\" <sep2> \"+test_d[15]\n",
    "val_d[16]=val_d[3]+\" <sep1> \"+val_d[14]+\" <sep2> \"+val_d[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "train_d[17]=train_d[16].apply(lambda x: TextBlob(x).sentiment)\n",
    "test_d[17]=test_d[16].apply(lambda x: TextBlob(x).sentiment)\n",
    "val_d[17]=val_d[16].apply(lambda x: TextBlob(x).sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d[\"polarity\"]=train_d[17].apply(lambda x: x[0])\n",
    "train_d[\"subjectivity\"]=train_d[17].apply(lambda x: x[1])\n",
    "train_d.drop(columns=[17],inplace=True)\n",
    "test_d[\"polarity\"]=test_d[17].apply(lambda x: x[0])\n",
    "test_d[\"subjectivity\"]=test_d[17].apply(lambda x: x[1])\n",
    "test_d.drop(columns=[17],inplace=True)\n",
    "val_d[\"polarity\"]=val_d[17].apply(lambda x: x[0])\n",
    "val_d[\"subjectivity\"]=val_d[17].apply(lambda x: x[1])\n",
    "val_d.drop(columns=[17],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=enc.fit(np.array(train_d[2]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out=l.transform(np.array(train_d[2]).reshape(-1,1)).toarray()\n",
    "test_out=l.transform(np.array(test_d[2]).reshape(-1,1)).toarray()\n",
    "val_out=l.transform(np.array(val_d[2]).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"output/val_out_onehot\",val_out)\n",
    "np.save(\"output/test_out_onehot\",test_out)\n",
    "np.save(\"output/train_out_onehot\",train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"onehot_encoder_decoder.plk\",\"wb\") as a:\n",
    "    pickle.dump(enc,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d.drop(axis=1,columns=[2,3,14,15],inplace=True)\n",
    "test_d.drop(axis=1,columns=[2,3,14,15],inplace=True)\n",
    "val_d.drop(axis=1,columns=[2,3,14,15],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d.to_csv(\"input/train.csv\")\n",
    "test_d.to_csv(\"input/test.csv\")\n",
    "val_d.to_csv(\"input/val.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
